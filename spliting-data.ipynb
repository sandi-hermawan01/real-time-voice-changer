{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "The next step is splitting the dataset, audio data that has been clean we do the split or separation of audio into small parts so that the training process will run smoothly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a variable declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy clean vocals file location\n",
    "url = \"./separated/htdemucs/botan-voice/vocals.wav\"\n",
    "#make our audio name\n",
    "AUDIO_NAME = \"botan-test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "install some required depedencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\sandi\\anaconda3\\lib\\site-packages (1.21.5)\n",
      "Requirement already satisfied: librosa in c:\\users\\sandi\\anaconda3\\lib\\site-packages (0.10.0.post2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from librosa) (1.9.1)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from librosa) (3.0.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from librosa) (0.3.5)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from librosa) (1.21.5)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from librosa) (0.55.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from librosa) (1.0.2)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from librosa) (4.3.0)\n",
      "Requirement already satisfied: pooch<1.7,>=1.0 in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.38.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (63.4.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from pooch<1.7,>=1.0->librosa) (2.28.1)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from pooch<1.7,>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from pooch<1.7,>=1.0->librosa) (21.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from packaging>=20.0->pooch<1.7,>=1.0->librosa) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (1.26.11)\n",
      "Requirement already satisfied: soundfile in c:\\users\\sandi\\anaconda3\\lib\\site-packages (0.12.1)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from soundfile) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sandi\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install numpy\n",
    "!python -m pip install librosa\n",
    "!python -m pip install soundfile\n",
    "import os\n",
    "os.makedirs(\"dataset/\"+AUDIO_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split The Audio into Smaller Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile\n",
    "\n",
    "\n",
    "# This function is obtained from librosa.\n",
    "def get_rms(\n",
    "    y,\n",
    "    *,\n",
    "    frame_length=2048,\n",
    "    hop_length=512,\n",
    "    pad_mode=\"constant\",\n",
    "):\n",
    "    padding = (int(frame_length // 2), int(frame_length // 2))\n",
    "    y = np.pad(y, padding, mode=pad_mode)\n",
    "\n",
    "    axis = -1\n",
    "    # put our new within-frame axis at the end for now\n",
    "    out_strides = y.strides + tuple([y.strides[axis]])\n",
    "    # Reduce the shape on the framing axis\n",
    "    x_shape_trimmed = list(y.shape)\n",
    "    x_shape_trimmed[axis] -= frame_length - 1\n",
    "    out_shape = tuple(x_shape_trimmed) + tuple([frame_length])\n",
    "    xw = np.lib.stride_tricks.as_strided(\n",
    "        y, shape=out_shape, strides=out_strides\n",
    "    )\n",
    "    if axis < 0:\n",
    "        target_axis = axis - 1\n",
    "    else:\n",
    "        target_axis = axis + 1\n",
    "    xw = np.moveaxis(xw, -1, target_axis)\n",
    "    # Downsample along the target axis\n",
    "    slices = [slice(None)] * xw.ndim\n",
    "    slices[axis] = slice(0, None, hop_length)\n",
    "    x = xw[tuple(slices)]\n",
    "\n",
    "    # Calculate power\n",
    "    power = np.mean(np.abs(x) ** 2, axis=-2, keepdims=True)\n",
    "\n",
    "    return np.sqrt(power)\n",
    "\n",
    "\n",
    "class Slicer:\n",
    "    def __init__(self,\n",
    "                 sr: int,\n",
    "                 threshold: float = -40.,\n",
    "                 min_length: int = 5000,\n",
    "                 min_interval: int = 300,\n",
    "                 hop_size: int = 20,\n",
    "                 max_sil_kept: int = 5000):\n",
    "        if not min_length >= min_interval >= hop_size:\n",
    "            raise ValueError('The following condition must be satisfied: min_length >= min_interval >= hop_size')\n",
    "        if not max_sil_kept >= hop_size:\n",
    "            raise ValueError('The following condition must be satisfied: max_sil_kept >= hop_size')\n",
    "        min_interval = sr * min_interval / 1000\n",
    "        self.threshold = 10 ** (threshold / 20.)\n",
    "        self.hop_size = round(sr * hop_size / 1000)\n",
    "        self.win_size = min(round(min_interval), 4 * self.hop_size)\n",
    "        self.min_length = round(sr * min_length / 1000 / self.hop_size)\n",
    "        self.min_interval = round(min_interval / self.hop_size)\n",
    "        self.max_sil_kept = round(sr * max_sil_kept / 1000 / self.hop_size)\n",
    "\n",
    "    def _apply_slice(self, waveform, begin, end):\n",
    "        if len(waveform.shape) > 1:\n",
    "            return waveform[:, begin * self.hop_size: min(waveform.shape[1], end * self.hop_size)]\n",
    "        else:\n",
    "            return waveform[begin * self.hop_size: min(waveform.shape[0], end * self.hop_size)]\n",
    "\n",
    "    def slice(self, waveform):\n",
    "        if len(waveform.shape) > 1:\n",
    "            samples = waveform.mean(axis=0)\n",
    "        else:\n",
    "            samples = waveform\n",
    "        if samples.shape[0] <= self.min_length:\n",
    "            return [waveform]\n",
    "        rms_list = get_rms(y=samples, frame_length=self.win_size, hop_length=self.hop_size).squeeze(0)\n",
    "        sil_tags = []\n",
    "        silence_start = None\n",
    "        clip_start = 0\n",
    "        for i, rms in enumerate(rms_list):\n",
    "            # Keep looping while frame is silent.\n",
    "            if rms < self.threshold:\n",
    "                # Record start of silent frames.\n",
    "                if silence_start is None:\n",
    "                    silence_start = i\n",
    "                continue\n",
    "            # Keep looping while frame is not silent and silence start has not been recorded.\n",
    "            if silence_start is None:\n",
    "                continue\n",
    "            # Clear recorded silence start if interval is not enough or clip is too short\n",
    "            is_leading_silence = silence_start == 0 and i > self.max_sil_kept\n",
    "            need_slice_middle = i - silence_start >= self.min_interval and i - clip_start >= self.min_length\n",
    "            if not is_leading_silence and not need_slice_middle:\n",
    "                silence_start = None\n",
    "                continue\n",
    "            # Need slicing. Record the range of silent frames to be removed.\n",
    "            if i - silence_start <= self.max_sil_kept:\n",
    "                pos = rms_list[silence_start: i + 1].argmin() + silence_start\n",
    "                if silence_start == 0:\n",
    "                    sil_tags.append((0, pos))\n",
    "                else:\n",
    "                    sil_tags.append((pos, pos))\n",
    "                clip_start = pos\n",
    "            elif i - silence_start <= self.max_sil_kept * 2:\n",
    "                pos = rms_list[i - self.max_sil_kept: silence_start + self.max_sil_kept + 1].argmin()\n",
    "                pos += i - self.max_sil_kept\n",
    "                pos_l = rms_list[silence_start: silence_start + self.max_sil_kept + 1].argmin() + silence_start\n",
    "                pos_r = rms_list[i - self.max_sil_kept: i + 1].argmin() + i - self.max_sil_kept\n",
    "                if silence_start == 0:\n",
    "                    sil_tags.append((0, pos_r))\n",
    "                    clip_start = pos_r\n",
    "                else:\n",
    "                    sil_tags.append((min(pos_l, pos), max(pos_r, pos)))\n",
    "                    clip_start = max(pos_r, pos)\n",
    "            else:\n",
    "                pos_l = rms_list[silence_start: silence_start + self.max_sil_kept + 1].argmin() + silence_start\n",
    "                pos_r = rms_list[i - self.max_sil_kept: i + 1].argmin() + i - self.max_sil_kept\n",
    "                if silence_start == 0:\n",
    "                    sil_tags.append((0, pos_r))\n",
    "                else:\n",
    "                    sil_tags.append((pos_l, pos_r))\n",
    "                clip_start = pos_r\n",
    "            silence_start = None\n",
    "        # Deal with trailing silence.\n",
    "        total_frames = rms_list.shape[0]\n",
    "        if silence_start is not None and total_frames - silence_start >= self.min_interval:\n",
    "            silence_end = min(total_frames, silence_start + self.max_sil_kept)\n",
    "            pos = rms_list[silence_start: silence_end + 1].argmin() + silence_start\n",
    "            sil_tags.append((pos, total_frames + 1))\n",
    "        # Apply and return slices.\n",
    "        if len(sil_tags) == 0:\n",
    "            return [waveform]\n",
    "        else:\n",
    "            chunks = []\n",
    "            if sil_tags[0][0] > 0:\n",
    "                chunks.append(self._apply_slice(waveform, 0, sil_tags[0][0]))\n",
    "            for i in range(len(sil_tags) - 1):\n",
    "                chunks.append(self._apply_slice(waveform, sil_tags[i][1], sil_tags[i + 1][0]))\n",
    "            if sil_tags[-1][1] < total_frames:\n",
    "                chunks.append(self._apply_slice(waveform, sil_tags[-1][1], total_frames))\n",
    "            return chunks\n",
    "\n",
    "audio, sr = librosa.load(url, sr=None, mono=False)  # Load an audio file with librosa.\n",
    "slicer = Slicer(\n",
    "    sr=sr,\n",
    "    threshold=-40,\n",
    "    min_length=5000,\n",
    "    min_interval=200,\n",
    "    hop_size=10,\n",
    "    max_sil_kept=500\n",
    ")\n",
    "chunks = slicer.slice(audio)\n",
    "for i, chunk in enumerate(chunks):\n",
    "    if len(chunk.shape) > 1:\n",
    "        chunk = chunk.T  # Swap axes if the audio is stereo.\n",
    "    soundfile.write(f'./dataset/{AUDIO_NAME}/split_{i}.wav', chunk, sr)  # Save sliced audio files with soundfile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yep you have successfully splitted the data, you can check in the dataset/our-audio-name file, good, let's go to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
